# Heal-Jimaku (治幕) - 使用指南

本文档将指导您如何使用 Heal-Jimaku (治幕) 应用程序来优化并导出您需要的字幕文件。

## 📋 前提条件

1.  **Heal-Jimaku 应用程序**:
    * 如果您从源码运行，请确保已按照 `README.md` 中的指导完成安装和依赖配置。
    * 如果您使用的是打包好的可执行文件，直接运行即可。
2.  **LLM API Key**: 您需要一个有效的大语言模型 API Key。此 API Key 主要用于文本的智能分割。默认支持 DeepSeek API，可以从 [DeepSeek 开放平台](https://platform.deepseek.com/) 注册并获取。使用其他模型或api服务（如OpenAI, Claude, Gemini或第三方公益站）需要在"LLM高级管理"窗口中自行修改对应的api地址、api格式以及模型名称。**请注意：由于程序采用摘要预处理和分块技术来优化长文本的分割效果，（比较长的）单个任务可能会产生多次API调用，请留意您的API账户额度和使用情况。**
3.  **输入文件**:
    * **本地 JSON 文件模式**: 一个包含文本和逐词时间戳的 JSON 文件。文件格式应为程序支持的几种格式之一 (详见下文)。
        * 您可以通过各种ASR服务（如ElevenLabs, Whisper, Deepgram, AssemblyAI）获取此类 JSON 输出。
        * 对于 ElevenLabs 的 JSON 文件, 您可以使用我写的另一个GUI小工具 [语音转字幕小帮手](https://github.com/fuxiaomoke/yuriyakuki) 来获取。
        * 或者，参考对应ASR服务商的官方文档使用控制台或试验场来获取 JSON 输出。
            * [ElevenLabs控制台](https://elevenlabs.io/docs/api-reference/speech-to-text/convert?explorer=true)
            * [Deepgram试验场](https://playground.deepgram.com/)
            * [Whisper参考文档](https://platform.openai.com/docs/guides/speech-to-text#overview)
            * [AssemblyAI试验场](https://www.assemblyai.com/playground)
        * 再或者，也可以使用自己或别人在本地或云端部署的转录模型来获取 JSON 文件。较为常见的就是各种whisper的微调模型。
    * **免费获取JSON模式**: 一个本地音频/视频文件（支持常见格式如 .mp3, .wav, .flac, .m4a, .mp4, .mov 等）。程序将使用集成的免费STT服务（当前为ElevenLabs）进行在线转录。

## 📄 输入 JSON 文件格式 (本地JSON模式)

当使用本地JSON文件时，Heal-Jimaku 支持解析来自不同ASR服务商的JSON输出。程序内部有针对以下格式的解析器：

* **ElevenLabs**: 包含 `"text"` (完整文本) 和 `"words"` (带 `"start"`, `"end"`, `"text"`/`"word"`, 可选 `"speaker_id"` 的词列表) 的JSON。
* **Whisper**: 通常包含 `"text"` (完整文本) 和 `"segments"` (片段列表，每个片段内含带 `"start"`, `"end"`, `"word"`/`"text"` 的词列表) 或直接的 `"words"` 列表。
* **Deepgram**: 具有特定嵌套结构，通常在 `"results"` -> `"channels"` -> `"alternatives"` 下找到 `"transcript"` (完整文本) 和 `"words"` (带 `"start"`, `"end"`, `"word"`/`"punctuated_word"`, 可选 `"speaker"` 的词列表)。
* **AssemblyAI**: 包含 `"text"` (完整文本) 和 `"words"` (带毫秒级 `"start"`, `"end"`, `"text"`, 可选 `"speaker"` 的词列表) 或通过 `"utterances"` 结构获取词列表。

**通用要求**:
无论源格式如何，程序期望能够从中提取出：

1.  一份完整的转录文本。
2.  一个包含逐个词语（或可识别的最小发音单元）及其精确开始和结束时间（单位：秒）的列表。**（注意，必须是word级时间戳的json）**

**示例 JSON 结构 (以ElevenLabs为例):**

```json
{
  "text": "そう、あの視線感じたので、そうなのかなって思って。(笑い)",
  "words": [
    {
      "text": "そ",
      "start": 22.719,
      "end": 22.859,
      "type": "word",
      "speaker_id": "speaker_0",
      "characters": null
    },
    {
      "text": "う",
      "start": 22.859,
      "end": 22.92,
      "type": "word",
      "speaker_id": "speaker_0",
      "characters": null
    },
    // ...更多词语...
    {
      "text": "(笑い)",
      "start": 31.059,
      "end": 32.399,
      "type": "audio_event",
      "speaker_id": "speaker_0",
      "characters": null
    }
  ]
}
```

程序会自动处理不同格式间的差异。您只需在界面上选择正确的源JSON格式。

## 🚀 启动应用程序

- **源码运行**

  在您的项目根目录（视您安装的情况可能还得激活虚拟环境），执行：

  Bash

  ```
  python src/main.py
  ```

- **可执行文件**: 直接双击运行 `治幕.exe` (Windows) 或对应的可执行文件。

## 🗔 界面概览

![Heal-Jimaku 应用截图](https://github.com/fuxiaomoke/heal-jimaku/blob/main/assets/screenshot.png)

Heal-Jimaku（治幕） 的主界面主要包含以下几个区域：

1. **标题栏与窗口控制**:
   - **SRT高级参数设置按钮 (⚙)**: 位于标题栏左侧，点击打开"自定义高级SRT参数"对话框。
   - **LLM高级管理按钮 (🤖)**: 位于SRT设置按钮旁边，点击打开"LLM高级设置"对话框，可配置**各种主流格式的**API地址、模型名称、温度等参数。
   - **背景设置按钮(🖼️):** 位于LLM高级管理按钮旁边，点击打开"背景设置"对话框，可选择程序主页面的背景图片的显示策略。
   - **标题**: 显示 "Heal-Jimaku (治幕)"。
   - **最小化按钮 (─)**: 将窗口最小化。
   - **关闭按钮 (×)**: 关闭应用程序。
   
2. **大模型 API KEY 设置**:
   - **API Key 输入框**: 用于输入您的大语言模型 API Key。默认为DeepSeek，可通过LLM高级设置配置**其他的API**。
   - **记住 API Key 复选框**: 勾选此项后，API Key 会被保存到配置文件中，下次启动时自动填充。
   
3. **文件选择**:
   - **JSON 文件输入框 / 音频文件提示:**
     - 在"本地JSON"模式下，显示当前选择的 JSON 文件的路径。
     - 在"免费获取JSON"模式下，会提示"通过"免费获取"模式提供音频文件"或显示已选音频文件名。
     
    - **浏览... (JSON 文件)**: 点击打开文件对话框，选择包含语音文本和时间戳的 JSON 文件。此按钮在"免费获取JSON"模式下禁用。**现在支持多文件选择，可进行批量处理。**
    - **免费获取JSON 按钮**: 点击打开"JSON输出参数设置"对话框，允许上传音频文件并设置免费转录时的相关参数。**现在支持多文件选择，可进行批量音频处理。**
   
    - **JSON 格式下拉框**: 选择输入JSON文件的来源/格式 (例如: ElevenLabs, Whisper, Deepgram, AssemblyAI)。此选项在"免费获取JSON"模式下会自动设为 "ElevenLabs(推荐)" 并禁用。
   
4. **拖拽处理功能（新功能！！！）**: 支持将JSON文件或媒体文件直接拖拽到主窗口中进行快速处理。拖拽时窗口会显示半透明的拖拽区域，提供直观的用户体验。

5. **导出与控制**:
   - **导出目录输入框**: 显示 SRT 字幕文件的保存目录。
   - **浏览... (导出目录)**: 点击打开目录选择对话框，选择 SRT 文件的保存位置。
   - **进度条**: 显示当前转换任务的进度，包括获取摘要、文本分块及逐块调用LLM进行分割的进度。
   - **开始转换按钮**: 点击开始处理输入（JSON文件或通过免费服务生成的JSON）并生成 SRT 字幕。
   
5. **日志区域**:
- 显示应用程序的运行日志、处理步骤、警告和错误信息。日志逻辑已优化，提供更清晰的反馈，**包括摘要生成、文本分块及逐块API调用的详细过程。**

## ⚙️ SRT参数设置

![Heal-Jimaku SRT高级设置截图](https://github.com/fuxiaomoke/heal-jimaku/blob/main/assets/settings_dialog.png)

点击主界面左上角的 **SRT高级参数设置按钮 (⚙)** 可以打开"自定义高级SRT参数"对话框。 在这里，您可以调整SRT字幕生成的一些关键参数，以更好地控制输出效果。

这些参数包括：

- **字幕最小持续时间 (秒)**: 字幕条目在屏幕上显示的目标最短时长。如果原始时长小于此值，程序会尝试延长显示时间（但不会超过其关联词语的合理范围或与其他字幕重叠）。默认值：`1.2` 秒。
- **字幕最大持续时间 (秒)**: 字幕条目在屏幕上显示的最长时长。如果一个片段转换后的字幕超过此值，程序会尝试将其分割成更短的条目。默认值：`12.0` 秒。
- **每行字幕最大字符数**: 一条字幕文本允许的最大字符数量。超过此数量的文本会被尝试分割。默认值：`60` 字符。
- **字幕间默认间隙 (毫秒)**: 两条连续字幕之间期望的最小时间间隔。程序会调整字幕的结束时间以尽量保证这个间隙，避免字幕快速切换。默认值：`100` 毫秒。

对话框中提供了"确定"、"取消"和"重置为默认值"的选项。 所做的更改在点击"确定"后会保存到配置文件中，并在后续转换任务中使用。

## 🤖 LLM高级设置

![Heal-Jimaku LLM高级设置截图](https://github.com/fuxiaomoke/heal-jimaku/blob/main/assets/llm_advanced_settings_dialog.png)

点击主界面左上角的 **LLM高级管理按钮 (🤖)** 可以打开"LLM高级管理"对话框。这个设置面板允许您配置大语言模型相关的高级参数：

- **模型配置列表**: 在左侧管理多个LLM配置。

  - **快速模板按钮**: 在左侧快速创建一个对应供应商的api配置模板，后续只需要填入对应apikey就能快速使用。
  - **添加新的配置按钮**: 在左侧创建一个新的自定义模板，需要手动填写相应参数，一般是使用公益站等第三方api 才会用到。
  - **删除当前配置按钮**: 删除右侧配置详情中展现的当前编辑的配置。

- **配置详情区域**: 填写配置的详细参数

  - **配置名称**: 为您的配置命名。
  - **API格式 **:
    - **关键功能**：选择您的API服务商兼容的格式。一般是使用第三方api时需要自己选，主流平台使用快速模板创建的配置里已经帮你选好了。
    - 选项包括：
      - **OpenAI兼容**: 适用于DeepSeek, OpenAI以及大多数第三方代理。
      - **Claude格式**: 适用于Anthropic的Claude API。
      - **Gemini格式**: 适用于Google的Gemini API。
      - **自动检测**: 程序将尝试根据API地址自动推断格式。
  - **API地址**: 配置LLM API的基础URL。
  - **模型**: 指定要使用的模型名称（可点击"获取模型"按钮尝试从API获取列表）。
  - **API Key**: 与主界面的API Key输入框联动，管理当前选中配置的Key。
  - **温度(0到2)**: 控制模型输出的随机性。默认值：`0.2`

- **操作区域**:

  - **测试连接**: 验证当前配置的API连接是否正常工作**（建议您使用非官方api前都先用这个按钮测试一下）**

  - **设为默认**: 将当前选中的配置设为默认启动配置**(实际实际获取srt时使用的配置)**。

- **对话框**还提供"保存配置"、"取消"按钮。通过这两个按钮保将修改的配置保存到配置文件中，或取消修改。

## 🔊 免费获取JSON (音频转文字参数设置)

![Heal-Jimaku JSON参数输出设置截图](https://github.com/fuxiaomoke/heal-jimaku/blob/main/assets/free_transcription_dialog.png)

点击主界面"文件选择"区域的 **"免费获取JSON"按钮**，会弹出"JSON输出参数设置"对话框。 此功能允许您直接上传音频或视频文件，使用集成的免费在线语音转文字服务（当前为 ElevenLabs）生成初步的带时间戳的JSON数据，随后 Heal-Jimaku 会自动使用此JSON数据进行后续的智能分割和SRT优化。

在此对话框中，您可以设置以下参数：

- 音频/视频文件:

  - **输入框**: 显示当前选择的音视频文件路径（只读）。
  - **浏览...**: 点击打开文件对话框，选择您要转录的本地音频/视频文件 (支持 `.mp3`, `.wav`, `.flac`, `.m4a`, `.ogg`, `.opus`, `.aac`, `.webm`, `.mp4`, `.mov` 等)。**现在支持多选文件进行批量处理**。
  - **温馨提示**: 上传文件时，**请控制文件大小小于300MB**（约为2个多小时的mp3的大小），避免超限导致的转录失败。如果是视频，强烈建议你先手动转换成MP3，然后再处理。
  
- 转录语言:

  - 下拉框选择转录的目标语言。选项包括"自动检测"、"日语"、"中文"、"英文"、“韩文”。默认为"自动检测"。

- 说话人数:

  - 下拉框选择音频中的说话人数。选项包括"自动检测" (API将尝试自动识别) 和 1 至 32 人。默认为"自动检测"。

- 生成非语音声音事件:

  - 复选框，勾选后，STT服务会尝试识别并标记非语音的声音事件（如掌声、笑声等）。默认为勾选。

对话框中同样提供了"确定"、"取消"和"重置"的选项。

- 点击 **"确定"** 后，如果已选择有效的音频文件，这些设置将被应用，主界面的输入模式会切换到"免费获取JSON"模式，JSON文件相关控件会被禁用，并显示所选音频文件的信息。
  - 于此同时，主窗口中绿色的"免费获取json"按钮会变成红色的"取消转录音频模式"按钮。点击这个红色按钮，将会放弃免费转录模式，主界面会尝试恢复到上次的本地JSON文件输入模式。
- 点击 **"取消"** 或关闭对话框，将放弃免费转录模式，主界面会尝试恢复到上次的本地JSON文件输入模式。
- 点击 **"重置"** ，各个参数将重置为默认值。

## 🖼️ 背景设置 (新增窗口)
![Heal-Jimaku 背景设置截图](https://github.com/fuxiaomoke/heal-jimaku/blob/main/assets/background_settings_dialog.png)

点击主界面左上角的 背景设置按钮(🖼️) 可以打开"背景设置"对话框。这个面板允许您自定义主窗口的背景显示策略。
您可以在以下四种模式中选择：

1. 默认背景图片轮播(推荐):
    • 这是默认选项。
    • 程序会从内置的 background 文件夹中随机选择图片作为背景。
2. 使用当前的背景图片作为固定背景:
    • 将当前主界面上显示的背景图固定下来作为背景，不再随机切换。
3. 选择自定义文件夹轮播背景图:
    • 允许您通过“自定义设置”区域的“浏览...”按钮选择一个包含您自己图片的文件夹。
    • 程序将随机轮播您指定文件夹中的图片。
4. 选择自定义图片作为固定背景:
    • 允许您通过“自定义设置”区域的“选择图片...”按钮选择一张特定的图片。
    • 程序将始终使用这张图片作为背景。

自定义设置区域：
    • 自定义文件夹: 当选择“自定义文件夹轮播”模式时，此输入框和“浏览...”按钮会激活，用于选择自定义图片文件夹。
    • 自定义固定图片: 当选择“自定义固定图片”模式时，此输入框和“选择图片...”按钮会激活，用于选择单张图片。

**支持的图片格式包括：PNG, JPG, JPEG, BMP, GIF。**

## 🆕 v0.2.0.0 新功能详细介绍

### 批量处理功能

Heal-Jimaku 现在支持批量处理多个文件，大大提高工作效率：

- **批量JSON处理**: 在"本地JSON"模式下，点击"浏览..."按钮时可以选择多个JSON文件进行批量处理。
- **批量音频处理**: 在"免费获取JSON"模式下，点击"浏览..."按钮时可以选择多个音频/视频文件进行批量处理。

**批量处理特点**:
- 自动识别文件数量，智能判断处理模式
- 批量音频处理时强制使用自动检测语言和说话人数，确保最佳转录效果
- 提供详细的处理进度和日志反馈，实时显示处理状态
- 处理完成后自动重置UI状态，准备下一次批量处理
- 智能错误处理：单个文件失败不会影响其他文件的处理

**批量处理操作流程**:
1. 在相应的模式下按住Ctrl键点击多个文件，或按住Shift键选择连续文件
2. 程序会自动检测到批量选择，显示文件数量信息
3. 点击"开始转换"后，程序会依次处理每个文件
4. 日志区域会显示每个文件的处理状态和结果
5. 全部完成后显示批量处理汇总信息

### 拖拽处理功能

支持通过拖拽方式快速处理文件，提供更直观的用户体验：

- **拖拽JSON文件**: 将JSON文件直接拖拽到窗口，支持单个或多个文件
- **拖拽媒体文件**: 将音频/视频文件直接拖拽到窗口，支持单个或多个文件
- **智能识别**: 程序会自动识别文件类型并设置相应的处理模式
- **非法混合检测**: 防止同时拖拽JSON和媒体文件，会弹出警告提示
- **视觉反馈**: 拖拽时窗口会显示半透明的拖拽区域，提供直观的用户体验

**拖拽处理特点**:
- 支持批量拖拽处理，可一次拖拽多个同类型文件
- 提供清晰的拖拽视觉反馈，拖拽区域会高亮显示
- 自动验证文件类型和合法性，防止错误操作
- 与现有处理逻辑无缝集成，无需改变使用习惯
- 拖拽后的操作流程与常规文件选择完全一致

**拖拽操作技巧**:
- 可以从文件资源管理器直接拖拽文件到程序窗口
- 支持从桌面拖拽文件快捷方式
- 拖拽时确保鼠标指针位于程序主窗口区域内
- 程序会自动检测并响应拖拽操作

## 🔄 批量处理与拖拽处理使用示例

### 批量处理示例

**示例1：批量处理JSON文件**
```
1. 选择"本地JSON"模式
2. 点击"浏览..."按钮
3. 按住Ctrl键选择多个JSON文件：episode1.json, episode2.json, episode3.json
4. 程序显示："已选择 3 个JSON文件进行批量处理"
5. 选择导出目录
6. 选择json文件格式
7. 点击"开始转换"
8. 程序依次处理每个文件，生成：episode1.srt, episode2.srt, episode3.srt
```

**示例2：批量处理音频文件**
```
1. 点击"免费获取JSON"按钮
2. 在对话框中点击"浏览..."选择音频文件
3. 按住Ctrl键选择多个音频文件：track1.mp3, track2.mp3, track3.mp3
4. 程序自动设置转录语言为"自动检测"，说话人数为"自动检测"，可根据自身情况手动调整。
5. 确认设置后点击"确定"
6. 选择导出目录
7. 点击"开始转换"
8. 程序依次转录并优化每个音频文件
```

### 拖拽处理示例

**示例1：拖拽JSON文件**
```
1. 确保程序处于"本地JSON"模式
2. 打开文件资源管理器，找到JSON文件
3. 直接拖拽文件到程序窗口
4. 程序自动识别文件类型并加载
5. 继续正常的处理流程
```

**示例2：拖拽音频文件**
```
1. 从文件资源管理器选择音频文件
2. 拖拽到程序窗口
3. 程序自动打开"JSON输出参数设置"对话框
4. 设置转录参数
5. 确认后继续处理流程
```

## 📝 操作步骤

应用程序提供两种主要的工作流程：

**A. 使用本地 JSON 文件进行优化**

1. 输入 API Key:

   - 在 "大模型 API KEY 设置"区域的 "API Key" 输入框中，粘贴您的 LLM API Key。
   - 如果您希望下次启动时自动填充，请勾选 "记住 API Key"。
2. (可选) 调整各项设置:

   - 点击主界面左上角的 **SRT高级参数设置按钮 (⚙)** 调整SRT字幕生成参数。
   - 点击主界面左上角的 **LLM高级设置按钮 (🤖)** 配置API地址、模型等LLM参数。
   - 根据您的需求调整相关参数，然后点击"确定"保存。如果不需要修改，可以跳过此步骤。
3. 选择 JSON 文件:

   - 确保主界面处于"本地JSON"模式（这是默认模式，或者如果您从"免费获取JSON"模式取消后也会恢复到此模式）。
   - 点击 "文件选择" 区域中 "JSON 文件" 旁边的 "浏览..." 按钮。**现在支持拖拽处理选择，可拖拽选择。**
   - 在弹出的文件对话框中，找到并选择您要处理的 JSON 文件。**现在支持多文件选择，可进行批量处理。**
4. 选择 JSON 格式:

   - 在 "文件选择" 区域的 "JSON 格式" 下拉框中，根据您的JSON文件来源选择对应的格式。
5. 选择导出目录:

   - 点击 "导出与控制" 区域中 "导出目录" 旁边的 "浏览..." 按钮。
   - 选择您希望保存生成的 SRT 文件的文件夹。
6. 开始转换:

   - 确认以上信息无误后，点击 "开始转换" 按钮。

**B. 使用"免费获取JSON"功能从音频直接生成优化字幕**

1. 输入 API Key:

   - 同上，确保 LLM API Key 已设置。这是后续文本分割所必需的。

2. (可选) 调整各项设置:

   - 您可以预先设置好期望的SRT输出参数和LLM配置。

3. 打开免费转录对话框:

   - 点击主界面"文件选择"区域的 **"免费获取JSON"按钮**。
   - 或者，您可以**直接使用拖拽功能，拖拽一个或多个媒体文件到主窗口中**。

4. 设置转录参数并选择音频文件:

   - 在弹出的"JSON输出参数设置"对话框中，点击"浏览..."选择您的音频/视频文件。**现在支持多文件选择，可进行批量音频处理。在批量音频处理模式下，转录语言和说话人数将强制使用自动检测，无法手动修改。**
   - 根据需要调整"转录语言"、"说话人数"和"生成非语音声音事件"等选项。
   - 点击"确定"。主界面将更新，JSON文件相关控件会被禁用，JSON输入框会显示您选择的音频文件名，"免费获取json"按钮变为"取消转录音频模式"按钮。
   
5. 选择导出目录:

   - 同上，选择SRT文件的保存位置。

6. 开始转换:

   - 点击 "开始转换" 按钮。程序会首先调用免费STT服务进行在线转录，生成JSON数据保存在导出目录，然后使用此数据进行后续的LLM智能分割和SRT优化。

**通用后续步骤 (两种模式共有)**:

1. 监控进度与日志:

   - 在转换过程中，您可以观察进度条的变化，该进度条会反映包括获取摘要、文本分块及逐块调用LLM进行分割的整体进度。
   - 日志区域会输出详细信息，包括与API的交互（免费STT API 和 LLM API）、**获取全文摘要的过程、文本如何被分块、逐块调用LLM API进行分割的情况**、文本片段的对齐情况、字幕条目的调整等。优化后的日志逻辑会提供更清晰的步骤说明。如果出现任何问题，错误信息也会在此显示。
   
2. 获取 SRT 文件:

   - 当转换完成后，进度条会达到 100%，并且会弹出提示框告知结果。
   - 生成的 SRT 文件将保存在您选择的导出目录中。
     - 对于本地JSON模式，SRT文件名通常与输入的JSON文件名相同（扩展名为.srt）。
     - 对于免费获取JSON模式，SRT文件名通常与上传的音频文件名相同（扩展名为.srt）。

## 📔 配置与日志文件

- 用户配置:

  - 路径: `~/.heal_jimaku_gui/config.json` (`~` 代表用户主目录)
  - 内容: 保存 API Key (可选)、上次使用的JSON/音频路径、上次使用的输出路径、上次选择的JSON格式、上次输入模式，以及图片管理相关参数、自定义的高级SRT参数、LLM配置参数和免费转录相关参数。
- 崩溃日志:

  - 路径: `~/.heal_jimaku_gui_logs/heal_jimaku_crashes.log`
- 内容: 如果应用程序意外崩溃，此文件会记录 Python 的错误回溯信息。

## 🔍 故障排查

- **"缺少信息" / "错误" 弹窗**:
  - 确保 API Key (用于LLM分割)、导出目录都已正确填写或选择。
  - **本地JSON模式**: 检查JSON文件路径是否已选择，文件是否存在且可读，并且其内容与所选的JSON格式相符。
  - **免费获取JSON模式**: 确保已通过对应对话框选择了一个有效的音频/视频文件。
  - 检查所选的导出目录是否存在且可写。
- **API 相关错误 (日志中显示)**:
  - **LLM API**:
    - **首选排查方式**: 请首先使用 **"LLM高级管理" (🤖) -> "测试连接"** 按钮。它会提供最直接的错误反馈（如API Key无效、模型名称错误等）。
    - **API格式配置错误**: 这是一个常见的错误点。请确保您在"LLM高级管理"中选择的 **"API格式"** 与您填写的 **"API地址"** 严格对应。（例如：DeepSeek/OpenAI 对应 "OpenAI兼容"；Anthropic 对应 "Claude格式"）。
    - **认证失败 (401/400/403)**: 请检查您的 API Key 是否正确，以及账户余额是否充足。不同服务商返回的代码不同（OpenAI/Claude: 401, Gemini: 400）。
    - **模型未找到 (404 Not Found)**: 检查您在"LLM高级管理"中填写的 "模型" 名称是否正确，或者"API格式"是否选错（例如用"OpenAI兼容"格式去请求一个Claude的模型名称）。
    - **请求超时 (Timeout)**: 网络连接问题或 LLM API 服务繁忙。可以稍后重试。**由于长文本处理包含多次API调用（摘要+分块分割），请确保网络连接在整个处理过程中保持稳定**。
    - **API 响应格式错误/内容为空**: 可能是 LLM API 临时问题，或输入文本过于特殊（例如过长，虽然已有分块但仍可能遇到边界情况）导致模型无法处理。**日志中会指明是摘要获取阶段还是特定文本块分割阶段出错**。
  - **免费STT服务 (如ElevenLabs)**:
    - **网络错误/超时**: 检查您的网络连接。免费服务可能因网络波动或服务本身负载较高而不稳定。
    - **文件格式/大小问题**: 确保上传的音频文件格式受支持且大小在服务限制内（免费服务对文件大小有300MB的限制）。
    - **API错误**: 日志中可能会显示来自STT服务的具体错误信息。
- **JSON 解析错误 / "无法获取LLM分割用文本" (日志中显示)**:
  - **本地JSON模式**: 确保您在 "JSON 格式" 下拉框中选择了与您的输入文件匹配的正确格式。检查JSON文件本身是否完整且符合其源服务商的规范。
  - **免费获取JSON模式**: 如果在线转录失败或返回的JSON不符合预期（非常罕见），可能会出现此问题。检查网络连接并重试。
- **"LLM 片段无法对齐" / "对齐相似度较低" (日志中显示)**:
  - 这表示 LLM API 返回的文本片段在原始带时间戳的词语中找不到足够相似的匹配。（代码中的v0.2.0.0版本已通过括号修正和时间戳校正算法优化了此问题）。
  - 如果仍然出现，原因可能包括：LLM对文本的改写程度较大、原始JSON中的完整文本字段与词语列表拼接内容不一致等。
  - 少量此类警告通常不影响整体字幕质量。
- **背景图片加载失败 (日志中显示)**:
  - **文件夹无效**: 检查 "背景设置" -> "自定义文件夹" 中选择的路径是否正确且存在。
  - **图片无效**: 检查 "背景设置" -> "自定义固定图片" 中选择的*文件*路径是否正确且存在。
  - **文件夹中没有支持的图片**: 确保您选择的文件夹中包含支持的格式 (PNG, JPG, JPEG, BMP, GIF)。
- **程序无响应**:
  - 如果转换的文件非常大（尤其是免费获取JSON模式下的大音频文件），API 调用（包括摘要和多次分块分割）和后续处理可能需要较长时间。请耐心等待日志区域的输出和进度条的更新。
- **程序崩溃 / 严重错误**:
  - 如果程序意外关闭，请检查位于 `~/.heal_jimaku_gui_logs/heal_jimaku_crashes.log` 的崩溃日志文件。
  - 如果您需要在 GitHub 提交 Issues，请附上此日志文件的内容。

## 🤔 其他问题

- 为啥一定要默认用DeepSeek的api，不能直接用免费接口或者其他更牛逼的大模型的接口嘛？
  - 现在程序已支持配置其他主流格式的API！通过LLM高级设置，您可以配置使用其他大语言模型服务。
  - 选ds最客观的原因是，在理解并分割日文文本 **（现已扩展至中文、英文、韩文）** 这个任务上，DeepSeek的性价比很高，兼顾了准确性和开销。
  - 另一个比较现实的原因是，DeepSeek是国产模型，不用怎么需要担心网络连接的问题。
  - 再说了，这个项目一开始是面向同人音声的台本开发的，不可描述的内容比较多，还是用个人付费api比较放心。
  - 而且，其他付费接口效果不一定比DeepSeek更好，可能最后答案没有多少差别，至于薅羊毛薅到的免费接口，那就更不清楚了。
  - 具体测试效果如下面这张图所示。 可以发现，DeepSeek-v3在面对这种标点符号识别数量很少的文本时，也能在系统提示词 **（现已经已进一步优化，此处图片仅做效果展示）** 的指导下输出不逊于顶尖模型的结果。唯一的不同仅仅是语气词、感叹词或迟疑词的处理，而这些短促的句子，在后续字幕合并优化时间戳的逻辑中是可以被统一的。相较之下，另一个被我寄予厚望的模型——qwen3，由于思考时间过长影响效率，以及实际输出结果不佳的缘故，最终被pass掉了。
    ![多个大模型测试统一文本的效果](https://github.com/fuxiaomoke/heal-jimaku/blob/main/assets/test-llm.png)
- 现在支持多种JSON格式了，哪个效果最好？ / "免费获取JSON"功能效果如何？
  - **本地JSON模式**: 程序本身对不同格式的解析能力是一致的，最终字幕质量更多取决于原始ASR服务商输出的JSON中，词语时间戳的准确性以及完整文本（尤其是标点断句）的质量。推荐选择您认为转录质量最高、时间戳最精确的服务商输出的JSON。带有 "(推荐)" 标记的格式（如ElevenLabs, Whisper）通常是因为这些服务商的模型效果比较好，建议优先尝试。[顺便强烈推荐各位音声同好试试这个我最近经常用的,whisper微调的 [日语特化模型](https://huggingface.co/efwkjn/whisper-ja-anime-v0.1) ，效果不输付费的ElevenLabs]
  - **免费获取JSON模式**: 此功能集成的STT服务（当前为ElevenLabs的免费API）旨在提供一个便捷、高质量的初始转录。其效果通常较好，尤其是对于清晰的常见语言音频。但免费服务可能在处理复杂音频（如多人、背景噪音大、口音特殊）时表现可能会不如付费模型。最终效果还取决于您对免费转录参数（语言、说话人数等）的设置。
- 为什么不直接把这个字幕优化功能加在上一个语音转字幕的项目里？/ "免费获取JSON"功能和之前的项目有什么关系？
  - 我希望前一个项目更加通用一些，不仅仅局限在日语音声的转录上。
  - 而本项目则会更多的聚焦在字幕优化导出上，特别是针对同人音声等场景，例如通过引入摘要理解上下文并对长文本进行分块处理来提升字幕分割质量。
  - 还有就是，我太菜了，又比较懒惰，所以......
  - 新增的"免费获取JSON"功能，其实已经借鉴并集成了类似我之前项目（"语音转字幕小帮手"）的核心转录逻辑，目标是为用户提供一个更流畅、从音频文件开始的一站式字幕优化体验，减少对外部工具的依赖。

## ⚠️ 注意！！！

使用 **Heal-Jimaku(治幕)** 生成的 SRT 文件的时间戳并不是百分百完美的。如果你需要翻译字幕文件，那么在翻译之前请务必先使用字幕编辑工具(比如:subtitle edit)进行简单的人工校对。放心，不符合审核要求的大部分字幕都已经被程序优化过了，你只需要稍微过一遍字幕，把那些我特地留下来的非常容易发现但程序无法处理的小问题手动解决一下即可。

如果遇到无法解决的问题，欢迎在项目的 GitHub Issues 页面提交详细的问题描述、相关的日志信息以及您的电脑环境和 Python 版本。