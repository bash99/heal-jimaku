# Heal-Jimaku (治幕) - 使用指南

本文档将指导您如何使用 Heal-Jimaku (治幕) 应用程序来优化并导出您需要的字幕文件。

## 📋 前提条件

1.  **Heal-Jimaku 应用程序**:
    * 如果您从源码运行，请确保已按照 `README.md` 中的指导完成安装和依赖配置。
    * 如果您使用的是打包好的可执行文件，直接运行即可。
2.  **LLM API Key**: 您需要一个有效的大语言模型 API Key。此 API Key 主要用于文本的智能分割和台本清洗。默认支持 DeepSeek API，可以从 [DeepSeek 开放平台](https://platform.deepseek.com/) 注册并获取。使用其他模型或api服务（如OpenAI, Claude, Gemini或第三方公益站）需要在"LLM高级管理"窗口中自行修改对应的api地址、api格式以及模型名称。**请注意：由于程序采用摘要预处理和分块技术来优化长文本的分割效果，（比较长的）单个任务可能会产生多次API调用，请留意您的API账户额度和使用情况。**
3.  **(可选) Soniox API Key 或者 ElevenLabs API Key**: 如果您想使用更私密更安全的付费云端转录功能，需要注册 [ElevenLabs](https://elevnlabs.io/) 或者 [Soniox](https://soniox.com/) 并获取 API Key。它们提供了高精度的多语言识别和说话人分离功能，特别适合应对不同复杂场景下的转录人物。

4.  **输入文件**:
    * **本地 JSON 文件模式**: 一个包含文本和逐词时间戳的 JSON 文件。文件格式应为程序支持的几种格式之一 (详见下文)。
        * 您可以通过各种ASR服务（如ElevenLabs, Soniox, Whisper, Deepgram, AssemblyAI）获取此类 JSON 输出。
        * 对于 ElevenLabs 的 JSON 文件, 您可以使用我写的另一个GUI小工具 [语音转字幕小帮手](https://github.com/fuxiaomoke/yuriyakuki) 来获取。(此功能目前已经集成到了本项目的云端转录功能中)
        * 或者，参考对应ASR服务商的官方文档使用控制台或试验场来获取 JSON 输出。
            * [ElevenLabs控制台](https://elevenlabs.io/docs/api-reference/speech-to-text/convert?explorer=true)
            * [Soniox控制台](https://console.soniox.com/)
            * [Deepgram试验场](https://playground.deepgram.com/)
            * [Whisper参考文档](https://platform.openai.com/docs/guides/speech-to-text#overview)
            * [AssemblyAI试验场](https://www.assemblyai.com/playground)
        * 再或者，也可以使用自己或别人在本地或云端部署的转录模型来获取 JSON 文件。较为常见的就是各种whisper的微调模型。
    * **免费获取JSON模式**: 一个本地音频/视频文件（支持常见格式如 .mp3, .wav, .flac, .m4a, .mp4, .mov 等）。程序将使用集成的免费STT服务（当前为ElevenLabs）进行在线转录。
    * **Elevenlabs 云端API转录：**一个本地音频/视频文件（支持常见格式如 .mp3, .wav, .flac, .m4a, .mp4, .mov 等）。
    * **Soniox 云端转录模式**: 一个本地音频/视频文件 + (可选但强烈推荐) 原始台本文件（支持 TXT, Word .docx, PDF 格式）。

## 📄 输入 JSON 文件格式 (本地JSON模式)

当使用本地JSON文件时，Heal-Jimaku 支持解析来自不同ASR服务商的JSON输出。程序内部有针对以下格式的解析器：

* **ElevenLabs**: 包含 `"text"` (完整文本) 和 `"words"` (带 `"start"`, `"end"`, `"text"`/`"word"`, 可选 `"speaker_id"` 的词列表) 的JSON。
* **Soniox**: 包含 `"text"` (完整文本) 和 `"tokens"` (带 `"start_ms"`, `"end_ms"`, `"text"`,`"confidence"`的词列表) 的JSON。
* **Whisper**: 通常包含 `"text"` (完整文本) 和 `"segments"` (片段列表，每个片段内含带 `"start"`, `"end"`, `"word"`/`"text"` 的词列表) 或直接的 `"words"` 列表。
* **Deepgram**: 具有特定嵌套结构，通常在 `"results"` -> `"channels"` -> `"alternatives"` 下找到 `"transcript"` (完整文本) 和 `"words"` (带 `"start"`, `"end"`, `"word"`/`"punctuated_word"`, 可选 `"speaker"` 的词列表)。
* **AssemblyAI**: 包含 `"text"` (完整文本) 和 `"words"` (带毫秒级 `"start"`, `"end"`, `"text"`, 可选 `"speaker"` 的词列表) 或通过 `"utterances"` 结构获取词列表。

**通用要求**:
无论源格式如何，程序期望能够从中提取出：

1.  一份完整的转录文本。
2.  一个包含逐个词语（或可识别的最小发音单元）及其精确开始和结束时间（单位：秒）的列表。**（注意，必须是word级时间戳的json）**

**示例 JSON 结构 (以ElevenLabs为例):**

```json
{
  "text": "そう、あの視線感じたので、そうなのかなって思って。(笑い)",
  "words": [
    {
      "text": "そ",
      "start": 22.719,
      "end": 22.859,
      "type": "word",
      "speaker_id": "speaker_0",
      "characters": null
    },
    {
      "text": "う",
      "start": 22.859,
      "end": 22.92,
      "type": "word",
      "speaker_id": "speaker_0",
      "characters": null
    },
    // ...更多词语...
    {
      "text": "(笑い)",
      "start": 31.059,
      "end": 32.399,
      "type": "audio_event",
      "speaker_id": "speaker_0",
      "characters": null
    }
  ]
}
```

程序会自动处理不同格式间的差异。您只需在界面上选择正确的源JSON格式。

## 🚀 启动应用程序

- **源码运行**

  在您的项目根目录（视您安装的情况可能还得激活虚拟环境），执行：

  ```bash
  python src/main.py
  ```

- **可执行文件**: 直接双击运行 `治幕.exe` (Windows) 或对应的可执行文件。

## 🗔 界面概览

![Heal-Jimaku 应用截图](https://raw.githubusercontent.com/fuxiaomoke/heal-jimaku/main/assets/screenshot.png)

Heal-Jimaku（治幕） 的主界面主要包含以下几个区域：

1. **标题栏与窗口控制**:
   - **SRT高级参数设置按钮 (⚙)**: 位于标题栏左侧，点击打开"自定义高级SRT参数"对话框。
   - **LLM高级管理按钮 (🤖)**: 位于SRT设置按钮旁边，点击打开"LLM高级设置"对话框，可配置**各种主流格式的**API地址、模型名称、温度等参数。
   - **背景设置按钮(🖼️):** 位于LLM高级管理按钮旁边，点击打开"背景设置"对话框，可选择程序主页面的背景图片的显示策略。
   - **标题**: 显示 "Heal-Jimaku (治幕)"。
   - **最小化按钮 (─)**: 将窗口最小化。
   - **关闭按钮 (×)**: 关闭应用程序。

2. **大模型 API KEY 设置**:
   - **API Key 输入框**: 用于输入您的大语言模型 API Key。默认为DeepSeek，可通过LLM高级设置配置**其他的API**。
   - **记住 API Key 复选框**: 勾选此项后，API Key 会被保存到配置文件中，下次启动时自动填充。

3. **文件选择**:
   - **JSON 文件输入框 / 音频文件提示:**
     - 在"本地JSON"模式下，显示当前选择的 JSON 文件的路径。
     - 在"云端转录"模式下，会显示已选音频文件名。

    - **浏览... (JSON 文件)**: 点击打开文件对话框，选择包含语音文本和时间戳的 JSON 文件。此按钮在"云端转录"模式下禁用。**现在支持多文件选择，可进行批量处理。**
    - **云端获取JSON按钮**: 点击打开"云端转录"对话框，允许上传音频文件并设置转录时的相关参数。**现在支持多文件选择，可进行批量音频处理。目前支持3种模式的转录（免费ElevenLabs、付费ElevenLabs、付费Soniox）。**

    - **JSON 格式下拉框**: 选择输入JSON文件的来源/格式 (例如: ElevenLabs, Soniox, Whisper, Deepgram, AssemblyAI)。此选项在"云端转录”模式下会自动设为对应的格式并禁用。

4. **拖拽处理功能**: 支持将JSON文件或媒体文件直接拖拽到主窗口中进行快速处理。拖拽时窗口会显示半透明的拖拽区域，提供直观的用户体验。

5. **导出与控制**:
   - **导出目录输入框**: 显示 SRT 字幕文件的保存目录。
   - **浏览... (导出目录)**: 点击打开目录选择对话框，选择 SRT 文件的保存位置。
   - **进度条**: 显示当前转换任务的进度，包括获取摘要、文本分块及逐块调用LLM进行分割的进度。
   - **开始转换按钮**: 点击开始处理输入（JSON文件或通过免费服务生成的JSON）并生成 SRT 字幕。
   - **启用AI自动校对复选框：** 仅使用Soniox转录时可用，勾选后会让大模型自动检测转录结果是否有漏字错字，同时会在修改后在导出目录生成详细的校对报告。
   
6. **日志区域**:
   - 显示应用程序的运行日志、处理步骤、警告和错误信息。日志逻辑已优化，提供更清晰的反馈，**包括摘要生成、文本分块及逐块API调用的详细过程。**
   - 用户友好的日志系统，提供实时进度状态和操作指导。

## ⚙️ SRT参数设置

![Heal-Jimaku SRT高级设置截图](https://raw.githubusercontent.com/fuxiaomoke/heal-jimaku/main/assets/settings_dialog.png)

点击主界面左上角的 **SRT高级参数设置按钮 (⚙)** 可以打开"自定义高级SRT参数"对话框。 在这里，您可以调整SRT字幕生成的一些关键参数，以更好地控制输出效果。

这些参数包括：

- **字幕最小持续时间 (秒)**: 字幕条目在屏幕上显示的目标最短时长。如果原始时长小于此值，程序会尝试延长显示时间（但不会超过其关联词语的合理范围或与其他字幕重叠）。默认值：`1.2` 秒。
- **字幕最大持续时间 (秒)**: 字幕条目在屏幕上显示的最长时长。如果一个片段转换后的字幕超过此值，程序会尝试将其分割成更短的条目。默认值：`12.0` 秒。
- **每行字幕最大字符数**: 一条字幕文本允许的最大字符数量。超过此数量的文本会被尝试分割。默认值：`60` 字符。
- **字幕间默认间隙 (毫秒)**: 两条连续字幕之间期望的最小时间间隔。程序会调整字幕的结束时间以尽量保证这个间隙，避免字幕快速切换。默认值：`100` 毫秒。

对话框中提供了"确定"、"取消"和"重置为默认值"的选项。 所做的更改在点击"确定"后会保存到配置文件中，并在后续转换任务中使用。

## 🤖 LLM高级设置 - 详细使用指南

![Heal-Jimaku LLM高级设置截图](https://raw.githubusercontent.com/fuxiaomoke/heal-jimaku/main/assets/llm_advanced_settings_dialog.png)

点击主界面左上角的 **LLM高级管理按钮 (🤖)** 可以打开"LLM高级管理"对话框。这是程序的核心配置面板之一，允许您配置大语言模型相关的所有参数。**本节将详细讲解如何配置各种主流LLM服务商的API，即使您是完全不懂技术的小白用户，也能轻松跟着步骤完成配置。**

### 界面布局说明

LLM高级管理对话框分为三个主要区域：

1. **左侧：配置列表管理区**
   - 显示您已保存的所有LLM配置
   - 快速模板按钮（DeepSeek、OpenAI、Claude、Gemini）
   - "添加新配置"按钮（用于自定义第三方API）
   - "删除当前配置"按钮

2. **右侧：配置详情编辑区**
   - 配置名称
   - API格式选择（重要！）
   - API地址
   - 模型名称
   - API Key 输入
   - 温度参数（0-1）

3. **底部：操作按钮区**
   - "测试连接"按钮（强烈建议每次配置后都测试）
   - "设为默认"按钮（设置默认使用的配置）
   - "保存配置"和"取消"按钮

### 📖 完整配置教程

下面将详细介绍如何配置各种主流LLM服务。**请根据您选择的服务商，跳转到对应的章节按步骤操作。**

---

### 🌟 方案一：配置 DeepSeek（推荐新手，性价比最高）

**为什么推荐 DeepSeek？**

- 国产模型，不需要科学上网
- 注册简单，支持微信支付宝充值
- 价格便宜（智能分割任务成本极低）
- 中日文处理能力强
- 对于类似同人音声的比较刺激的内容接受度较高，甲比较薄，不用担心内容审核

**第一步：注册 DeepSeek 账号并获取 API Key**

1. 访问 [DeepSeek 开放平台](https://platform.deepseek.com/)
2. 点击右上角"注册"按钮，使用手机号或邮箱注册
3. 登录后，点击左侧菜单的 **"API Keys"**
4. 点击 **"创建 API Key"** 按钮
5. 给您的 Key 起个名字（比如"治幕专用"），然后点击确认
6. **重要**：复制生成的 API Key（类似 `sk-xxxxxxxxxxxxx` 的格式），并妥善保存。**这个 Key 只会显示一次，关闭后无法再查看！**

**第二步：在 Heal-Jimaku 中配置 DeepSeek**

​	**快速配置（新手推荐）：**

1. 打开 Heal-Jimaku，在主窗口的“大模型API Key”处，粘贴您刚才复制的 DeepSeek API Key
2. 点击右侧的的 **"测试连接"** 按钮
   - 如果显示"✅ 连接成功！模型响应正常"，说明配置正确
   - 如果出现错误，请检查 API Key 是否完整复制，以及账户是否有余额
3. 测试成功后，记得勾选 **“记住 API Key”** 复选框，就算完成快速配置啦

​	**详细配置：**

1. 打开 Heal-Jimaku，点击主界面左上角的 **🤖 LLM高级管理** 按钮
2. 在弹出的对话框左侧，点击 **"DeepSeek"** 快速模板按钮（或直接编辑默认的 **"DeepSeek"** 配置）
3. 此时右侧会自动填入 DeepSeek 的配置模板：
   - **配置名称**：DeepSeek
   - **API格式**：OpenAI兼容或自动检测（已自动选择，不要改）
   - **API地址**：`https://api.deepseek.com/v1`（已自动填入，不要改）
   - **模型**：`deepseek-chat`（已自动填入，推荐使用）
   - **温度**：`0.2`（默认值，不建议修改）
4. 在 **"API Key"** 输入框中，粘贴您刚才复制的 DeepSeek API Key
5. 点击右下角的 **"测试连接"** 按钮
   - 如果显示"✅ 连接成功！模型响应正常"，说明配置正确
   - 如果出现错误，请检查 API Key 是否完整复制，以及账户是否有余额
6. 测试成功后，点击 **"设为默认"** 按钮，将此配置设为默认使用
7. 最后点击 **"保存配置"** 按钮，完成设置

**第三步：充值（如果需要）**

- DeepSeek 新用户通常会赠送一定额度的免费试用
- 如果提示余额不足，可以在 DeepSeek 平台的"账户余额"页面充值
- 推荐充值 10-20 元即可使用很长时间（智能分割任务成本极低，10-20元足够您使用1~2年了）

**✅ 完成！** 现在您可以开始使用 Heal-Jimaku 进行字幕优化了。

---

### 🔵 方案二：配置 OpenAI（适合有科学上网条件的用户）

**注意事项：**
- 需要科学上网访问 OpenAI 官网
- 需要国外信用卡或虚拟卡充值
- 价格相对较高

**第一步：获取 OpenAI API Key**

1. 访问 [OpenAI Platform](https://platform.openai.com/)（需科学上网）
2. 注册并登录账号
3. 点击右上角头像 -> **"Your Profile"**
4. 点击 **"User API keys"** 
4. 再点击 **"Create new secret key"** -> **"Create secret key"**
5. 复制生成的 API Key（格式类似 `sk-xxxxxxxxxxxxx`）**这个 Key 只会显示一次，关闭后无法再查看，请妥善保管！**

**第二步：在 Heal-Jimaku 中配置**

1. 打开 **LLM高级管理** 对话框
2. 点击左侧的 **"OpenAI"** 快速模板按钮
3. 系统会自动填入：
   - **API格式**：OpenAI兼容
   - **API地址**：`https://api.openai.com/v1`
   - **模型**：`gpt-4o-mini`（推荐，性价比高）或 `gpt-3.5-turbo`
4. 粘贴您的 OpenAI API Key
5. 点击 **"测试连接"** 验证
6. 测试成功后，点击 **"获取模型"** ，可以看到当前可选择的模型列表
6. 选择好自己要使用的模型后，点击 **"设为默认"** 和 **"保存配置"**

**模型选择建议：**

- `gpt-5.1-chat-latest`：推荐，效果好
- `gpt-4o-mini`：更便宜，性价比高

---

### 🟣 方案三：配置 Claude（Anthropic）

**注意事项：**
- 需要科学上网
- 支持国外信用卡或部分虚拟卡
- 并不适用于有年龄限制的场景（甲太厚了）

**第一步：获取 Claude API Key**

1. 访问 [Anthropic Console](https://console.anthropic.com/)（需科学上网）
2. 注册并登录
3. 进入 **"Get API Key"** 页面（需使用虚拟卡，进行一系列复杂操作）
4. 点击 **"Create Key"**
5. 复制生成的 API Key（格式类似 `sk-xxxxxxxxxxxxx`）

**第二步：在 Heal-Jimaku 中配置**

1. 打开 **LLM高级管理** 对话框
2. 点击左侧的 **"Claude"** 快速模板按钮
3. 系统会自动填入：
   - **API格式**：Claude格式（**注意：这里必须是 Claude 格式，不是 OpenAI 兼容！**）
   - **API地址**：`https://api.anthropic.com/v1/messages`
   - **模型**：`claude-sonnet-4-5-20250929`（推荐）
4. 粘贴您的 Claude API Key
5. 点击 **"测试连接"** 验证
6. 测试成功后，选择合适的模型，点击 **"设为默认"** 和 **"保存配置"**

**常见错误：**
- 如果提示"API格式错误"，请确保 **API格式** 选择的是 **"Claude格式"**，而不是 "OpenAI兼容"

---

### 🟢 方案四：配置 Gemini（Google）

**注意事项：**
- 需要科学上网
- 部分模型免费（有配额限制）

**第一步：获取 Gemini API Key**

1. 访问 [Google AI Studio](https://aistudio.google.com/)
2. 登录您的 Google 账号
3. 点击左下角的 **"Get API Key"**
4. 点击右上角 **"创建 API 密钥"**
4. 新建一个项目，为api key起一个名字，点击 **"创建密钥"**
5. 复制生成的 API Key

**第二步：在 Heal-Jimaku 中配置**

1. 打开 **LLM高级管理** 对话框
2. 点击左侧的 **"Gemini"** 快速模板按钮
3. 系统会自动填入：
   - **API格式**：Gemini格式
   - **API地址**：`https://generativelanguage.googleapis.com/v1beta`
4. 粘贴您的 Gemini API Key
5. 点击 **"测试连接"** 验证
6. 测试成功后，点击 **"获取模型"** ，可以看到当前可选择的模型列表
6. 点击 **"设为默认"** 和 **"保存配置"**

**模型选择建议：**

- `gemini-2.5-flash`：速度快，处理分割这样的简单任务效果好，免费
- `gemini-3-pro`：更聪明，性价比不错，绑卡就有300刀的赠金可用

---

### 🌐 方案五：配置第三方公益API（免费但需谨慎）

**什么是第三方公益API？**
一些技术社区或个人会提供免费的中转API服务，通常兼容 OpenAI 格式。这些服务可能免费，但**稳定性和隐私性无法保证**。

**如何找到公益API？**

- 推荐访问 [LINUX DO 论坛](https://linux.do/) 的相关板块
- 搜索"公益API"、"免费LLM"等关键词
- **注意**：使用前请确认来源可靠性，避免泄露敏感信息

**配置步骤**

1. 打开 **LLM高级管理** 对话框
2. 点击左侧的 **"添加新配置"** 按钮
3. 手动填写配置信息：
   - **配置名称**：比如"某某公益站"
   - **API格式**：通常选择 **"OpenAI兼容"**（具体看API提供方说明）
   - **API地址**：填入公益站提供的地址（比如 `https://xxxxx.com/v1`）
   - **模型**：填入公益站支持的模型名称（或者点击 **"获取模型"** 按钮，从刷新的模型列表中选择）
   - **API Key**：填入公益站提供的 Key（有些公益站不需要 Key，可填 `sk-xxxxx` 占位）
4. **必须测试连接**：点击 **"测试连接"** 按钮，确保能正常工作
5. 测试成功后，点击 **"设为默认"** 和 **"保存配置"**

**⚠️ 风险提示：**
- 公益API可能随时失效
- 不建议用于处理过于隐私的内容
- 响应速度和稳定性可能较差
- 需要考虑安全审查问题

---

### 🔧 参数详解

#### API格式选择（非常重要！）

**这是最容易出错的地方！** 不同的服务商使用不同的API格式，必须正确选择：

- **OpenAI兼容**：适用于 DeepSeek、OpenAI、大多数第三方公益站
- **Claude格式**：仅适用于 Anthropic 的 Claude API
- **Gemini格式**：仅适用于 Google 的 Gemini API
- **自动检测**：让程序尝试自动推断（不推荐新手使用）

**常见错误示例：**
- ❌ 使用 Claude API，但选择了"OpenAI兼容"格式 → 会报错"API格式错误"
- ❌ 使用 DeepSeek API，但选择了"Claude格式" → 会报错"认证失败"

#### 模型名称填写

不同服务商的模型名称不同，必须准确填写：

| 服务商 | 推荐模型名称 | 说明 |
|--------|------------|------|
| DeepSeek | `deepseek-chat` | 默认模型，性价比最高 |
| OpenAI | `gpt-5.1-chat-latest` 或 `gpt-4o-mini` | 4o-mini 推荐 |
| Claude | `claude-sonnet-4-5-20250929` | 最新版本模型，但是有甲 |
| Gemini | `gemini-2.5-flash` | 免费且快速 |

**提示**：点击"获取模型"按钮，程序会尝试从API自动获取可用模型列表。

#### 温度参数调节

温度参数控制模型输出的随机性：

- **0.0-0.3**：输出非常确定，适合需要精确结果的任务（**推荐用于字幕分割**）
- **0.4-0.7**：输出较为平衡
- **0.8-1.0**：输出更有创意和多样性（不推荐用于字幕分割）

**DeepSeek 的温度默认值 0.2 已经过多次实践检验，不建议修改。**

---

### 🔍 测试连接功能详解

**为什么要测试连接？**
测试连接可以验证您的配置是否正确，避免在实际使用时才发现错误。

**测试连接会做什么？**
1. 向您配置的API发送一个简单的测试请求
2. 验证API Key是否有效
3. 验证模型名称是否正确
4. 检查API格式是否匹配
5. 确认账户余额是否充足

**可能的测试结果：**

✅ **"连接成功！模型响应正常"**
- 恭喜！配置完全正确，可以正常使用

❌ **"认证失败 (401)"**
- API Key 错误或已失效
- 解决方法：检查 API Key 是否完整复制，重新生成新的 Key

❌ **"模型未找到 (404)"**
- 模型名称填写错误
- 解决方法：检查模型名称拼写，参考服务商官方文档

❌ **"API格式配置错误"**
- API格式选择与实际服务商不匹配
- 解决方法：确保选择了正确的API格式（比如 Claude 必须选"Claude格式"）

❌ **"账户余额不足"**
- 账户没有充值或额度用完
- 解决方法：前往服务商平台充值

❌ **"连接超时 (Timeout)"**
- 网络问题或服务商服务器繁忙
- 解决方法：检查网络连接，稍后重试，或使用科学上网工具

---

### 📚 多配置管理技巧

**为什么需要多个配置？**

- 不同场景使用不同的模型（比如测试用免费API，正式用付费API）
- 备用配置（当主力API失效时切换）
- 对比不同模型的效果

**如何管理多个配置？**

1. **添加新配置**：点击左侧"添加新配置"按钮或快速模板按钮
2. **切换配置**：点击左侧配置列表中的任一配置，右侧会显示其详细信息
3. **设为默认**：选中某个配置后，点击"设为默认"按钮，该配置会在程序启动时自动使用
4. **删除配置**：选中某个配置后，点击"删除当前配置"按钮（默认配置无法删除）

**最佳实践：**

- 保留至少2个可用配置作为备份
- 给配置起有意义的名字（比如"DeepSeek主力"、"Gemini备用"）
- 定期测试备用配置是否可用

---

### ❓ 常见问题FAQ

**Q1: 我配置了 DeepSeek，但提示"认证失败"？**

A: 请检查：
1. API Key 是否完整复制（不要有多余的空格）
2. API Key 是否已过期或被删除
3. 账户余额是否充足
4. API格式是否选择错误

**Q2: 测试连接成功，但实际使用时报错？**

A: 可能原因：
1. 账户余额在测试后用完了
2. API服务商限流（短时间内调用次数过多）
3. 网络连接不稳定
4. 尝试切换到备用配置

**Q3: 使用公益API安全吗？**

A: 存在风险：
- 您发送的文本内容会经过第三方服务器
- 如果处理的是敏感内容（如不可描述的音声台词），建议使用官方付费API
- 公益API可能随时失效

**Q4: 哪个LLM服务商最适合我？**

A: 推荐选择：
- **预算有限 + 国内用户**：DeepSeek（性价比最高）
- **追求最佳效果 + 有科学上网**：无脑选择 Gemini
- **想白嫖nb的模型**：公益API

**Q5: 温度参数设置多少合适？**

A:推荐使用0.2：
- 默认值 0.2 已经过优化，适合字幕分割任务
- 不建议超过 0.5，否则可能导致分割结果不稳定

---

## 🔊 云端获取JSON (音频转文字参数设置)

点击主界面"文件选择"区域的 **"云端获取JSON"** 按钮（或者将一个或多个音视频文件直接拖拽到主窗口），会弹出 **"云端转录"** 对话框。 此功能允许您直接上传音频或视频文件，使用集成的免费在线语音转文字服务生成初步的带时间戳的JSON数据，随后 Heal-Jimaku 会自动使用此JSON数据进行后续的智能分割和SRT优化。

目前，目前一共集成了3种现在一共集成了3种转入服务商，分别是**ElevenLabs免费版**、**ElevenLabs付费版**和**soniox付费版**。您可以在**"云端转录"** 对话框中通过 **"转录服务商"** 下拉列表自行设置。

![Heal-Jimaku 免费ElevenLabs弹窗截图](https://raw.githubusercontent.com/fuxiaomoke/heal-jimaku/main/assets/elevenlabs_transcription_dialog.png)

在选择了**ElevenLabs** 的服务后（无论是否免费），您可以设置以下参数：

- **音频/视频文件**:

  - **输入框**: 显示当前选择的音视频文件路径（只读）。
  - **浏览...**: 点击打开文件对话框，选择您要转录的本地音频/视频文件 (支持 `.mp3`, `.wav`, `.flac`, `.m4a`, `.ogg`, `.opus`, `.aac`, `.webm`, `.mp4`, `.mov` 等)。**现在支持多选文件进行批量处理**。
  - **温馨提示**: 使用免费版上传文件时，**请控制文件大小小于300MB**（约为2个多小时的mp3的大小），避免超限导致的转录失败。如果是视频，强烈建议你先手动转换成MP3，然后再处理。
- **转录语言**:
- 下拉框选择转录的目标语言。选项包括"自动检测"、"日语"、"中文"、"英文"、"韩文"。默认为"自动检测"。
- **说话人数**:
- 下拉框选择音频中的说话人数。选项包括"自动检测" (API将尝试自动识别) 和 1 至 32 人。默认为"自动检测"。
- **生成非语音声音事件**:
- 复选框，勾选后，STT服务会尝试识别并标记非语音的声音事件（如掌声、笑声等）。免费版默认为勾选，付费版默认不勾选。

![Heal-Jimaku 付费ElevenLabs弹窗截图](https://raw.githubusercontent.com/fuxiaomoke/heal-jimaku/main/assets/elevenlabs_vip_transcription_dialog.png)

在选择了**ElevenLabs** 的**付费服务**后，您需要自行配置**ElevenLabs**的**API key**，可以通过测试连接按钮测试连接是否正常。此模式下，您可以选择不启用说话人分离功能，在免费版中，这个功能是强制启用的。付费版相较于免费版最大的优势在于文件大小的限制更宽松，不需要再拘泥于文件格式，因为付费版只根据音视频的时长决定开销。另外，付费版上传的媒体内容可以自行管理，而免费版的媒体内容有被拿去作为训练模型的数据的可能，请根据您的实际情况使用。

对话框中同样提供了"确定"和"取消"的选项。

- 点击 **"确定"** 后，如果已选择有效的音频文件，这些设置将被应用，主界面的输入模式会切换到"云端获取JSON"模式，JSON文件相关控件会被禁用，并显示所选音频文件的信息。
  - 于此同时，主窗口中绿色的"云端获取JSON"按钮会变成红色的"取消云端转录"按钮。点击这个红色按钮，将会放弃免费转录模式，主界面会尝试恢复到上次的本地JSON文件输入模式。
- 点击 **"取消"** 或关闭对话框，将放弃免费转录模式，主界面会尝试恢复到上次的本地JSON文件输入模式。

接下来详细讲述选择了**"Soniox"**为服务商时的云端转录设置。👇

## 🎯 Soniox 云端转录设置（全新功能！）

![Heal-Jimaku Soniox转录弹窗截图](https://raw.githubusercontent.com/fuxiaomoke/heal-jimaku/main/assets/soniox_transcription_dialog.png)

### 什么是 Soniox？为什么要使用它？

**Soniox** 是一款业界领先的高精度语音识别服务，相比其他主流STT服务，Soniox 在以下方面具有显著优势：

✨ **核心优势：**

1. **超高识别精度**：
   - 专有名词识别准确率极高（尤其是日语人名、地名）
   - 口语化表达处理更准确
2. **Context 上下文功能**（🌟革命性特性）：
   - 支持导入台本作为"上下文"
   - 显著提升专有名词识别率（提升 30-50%）
   - 特别适合同人音声、广播剧等有剧本的内容
3. **说话人分离（Diarization）**：
   - 自动识别不同说话人
   - 准确标记每句话的说话人ID
   - 适合多人对话的音声
4. **多语言支持**：
   - 支持中文、日语、英语、韩语等多种语言
   - **混合语言识别能力强**
5. **非常便宜划算的价格**
   - 相较于EleveLabs付费版便宜了大概**5倍**左右
   - 在经过程序优化后性能可以达到ElevenLabs的85%到90%，而且时间轴更好看


**💡 适用场景：**
- 同人音声转录（特别是有台本的）
- 广播剧、有声书转录
- 包含大量专有名词的内容
- 需要区分多个说话人的音频
- 时间戳要求高的项目

**💰 成本说明：**
- Soniox 是付费服务，按转录token计费
- 价格正如上面所说，相对 ElevenLabs 官方API 便宜很多（一小时音频大约需要6~8美分，折合人民币4~5毛钱），但精度也不差
- 具体价格请参考 [Soniox 官方定价](https://soniox.com/pricing)

---

### 如何注册 Soniox 并获取 API Key？

**第一步：注册 Soniox 账号**

1. 访问 [Soniox 官网](https://soniox.com/)
2. 点击右上角 **"Get API Key"** 按钮登录
3. 填写注册信息（邮箱、密码）
4. 验证邮箱并登录

**第二步：获取 API Key**

1. 登录后，进入 [Soniox Console](https://console.soniox.com/)
2. 点击左侧菜单的 **"API Keys"**
3. 点击 **"Create API Key"** 按钮
4. 给您的 Key 起个名字（比如"治幕专用"）
5. 复制生成的 API Key（格式类似 `soniox_xxxxxxxxxxxxx`）
6. **妥善保存此 Key**，好消息是关闭后可以再次查看

**第三步：充值**

- Soniox 偶尔会赠送免费额度给新用户，但最近活动结束了
- 如需正式使用，需要在 Console 的 "Billing" 页面绑定信用卡或虚拟卡来充值

---

### Soniox 转录对话框详细说明

点击 **"云端获取JSON"** 弹窗的 **"转录服务商"下拉列表**，会弹出 Soniox 的选项，点击后切换到专用的设置页面。

#### 界面布局

对话框分为以下几个区域：

1. **音频文件选择区**
2. **转录参数配置区**
   - API Key 配置区
   - 基础参数配置区
   - **context 优化区**（可选但强烈推荐）


---

### 📝 Soniox转录中常用参数说明

#### 1. 音频/视频文件

- **输入框**：显示当前选择的音视频文件路径（只读）
- **浏览... 按钮**：点击选择您要转录的音频/视频文件
  - 支持格式：`.mp3`, `.wav`, `.flac`, `.m4a`, `.ogg`, `.opus`, `.aac`, `.webm`, `.mp4`, `.mov` 等
  - **支持批量选择**：可一次选择多个文件进行批量转录
- **文件限制**：文件大小无限制，但时长不能超过300分钟

#### 2. 台本文件上传（Context功能）🌟

**这是 Soniox 的杀手级功能！强烈推荐使用！**

- **什么是Context？**
  - 就是上下文，可以是结构化的，也可以是非结构化的
- **为什么要上传台本？**
  - **极大提升专有名词识别率**（角色名、地名、技能名等）
  - **可以帮助转录模型更好的理解转录的场景**
  - **提升生僻词识别准确率**
  - **提高整体转录质量20-30%**
- **支持的台本格式**：
  - **TXT 纯文本**：最简单，直接复制粘贴台词即可
  - **Word 文档 (.docx)**：支持标准 Word 格式
  - **PDF 文档**：程序会自动调用 OCR 识别（可以配合 LLM进行内容清洗优化）
- **⚠️ 重要提示**：
  - 上传PDF台本后，程序会**自动进行本地噪声清洗（去除ocr识别中的噪声）**
  - 本地清洗后，可选择**调用LLM进行智能清洗**
  - 智能清洗过程会去除拟声词、音效标记、动作描述**（但保留内心独白、自言自语）**

#### 3. 转录语言（语言提示）

下拉选择该音频的主要语言：

- **根据音频自行设置**（推荐）：设置越精准，效果越好。由于soniox的强项是混合语言识别（比如日语+英语），因此强烈推荐自己设置语言。
- 或者取消所有勾选，开启下方的**启用语言识别**复选框

**💡 小贴士**：

- **语言识别复选框**的勾选与上面自行设置的**语言提示**不冲突，可以同时选择

#### 4. 说话人分离（Diarization）

通过复选框的勾选与否，决定是否分离说话人，勾选后，模型会自行判断说话人数，并分离每句话的所属

#### 5. 启用 Soniox AI 后处理

在主界面json格式旁边的复选框，勾选后，程序会在转录完成后调用 LLM 对结果进行二次校对。

**AI 后处理功能**：

- 智能修正发音相似但逻辑不通的错别字
- 优化标点符号
- 修正语序错误
- 输出更详细的校对报告

**是否勾选？**
- ✅ 推荐勾选（需要额外消耗 LLM API 调用次数）
- ❌ 如果希望节省成本，可不勾选

**⚠️ 前提条件**：

- 必须已配置好 LLM API Key
- 会额外消耗 LLM API 额度

---

### 🚀 完整操作流程示例

下面通过一个实际例子，演示如何使用 Soniox 转录一个带台本的同人音声。

**场景**：您有一个日语同人音声音频文件 `RJ123456.mp3`，以及对应的台本文件 `台本.txt`

**第一步：准备台本文件**

1. 检查您的台本文件（TXT、Word 或 PDF 格式）
2. 确保台本内容包含所有对话、旁白
3. 台本可以包含拟声词、音效标记（如 [开门声]），程序会自动清洗

**示例台本内容**：

```
第一幕：相遇

[开门声]

角色A：你好，初次见面。我是艾莉娅·冯·埃伦贝格。

[脚步声]

角色B：啊、那个……请问是来应聘的吗？

角色A：嗯啊~就是这样的……(小声说话)

[音乐响起]
```

**第二步：打开 Soniox 转录对话框**

1. （可选）配置好 **LLM API Key**（台本清洗以及AI校对时需要用到）
2. 配置好 **Soniox API Key**（必须配置）
3. 在主界面点击 **"云端获取JSON"** 按钮，在 "转录服务商" 中选择 Soniox

**第三步：配置转录参数**

1. **选择音频文件**：
   - 点击"浏览..."按钮（或者一开始就直接把音频文件拖拽到主窗口里）
   - 选择 `RJ123456.mp3`
   - 确认文件已加载

2. **上传台本文件**：
   - 点击"导入台本"按钮
   - 选择 `台本.txt`（`台本.docx`、`台本.pdf`）
   - 确认台本已加载
     - 如果是pdf，应该会提示“ocr识别中”，请耐心等待20~120秒
     - txt和docx，应该很快就会弹出窗口
   - 程序会提示您"是否选择llm清洗台本内容"
     - 若您不选择，那么当前台本内容会填充进"剧情设定"文本框
     - 若选择了llm清洗，则会提示 "llm清洗中"，请再耐心等待1~3分钟，结束清洗后，会弹出清洗成功的窗口，清洗后的台本内容会填充进"剧情设定"文本框
   
   **💡 小贴士**：
   
   - 您可以自由编辑上传后的台本
   - 您可以选择编辑专有名词（一行一个），提高转录质量
   
3. **设置转录语言**：
   
   - 选择 **"日语"**（假如这是日语音声）
   
4. **设置说话人**：
   
   - 启用说话人分离即可

6. **启用 Soniox AI 后处理（点击确定按钮后）**：
   
   - ✅ **勾选**（获得最佳转录质量）

**第四步：开始转录**

1. 确认所有设置无误
2. 点击 **"确定"** 按钮
3. 主界面会显示"Soniox转录模式已启用"
4. 点击主界面的 **"开始转换"** 按钮

**第五步：监控转录进度**

1. **开始转录**：
   - 日志显示："Soniox 转录进行中"的提示
   - 进度条实时更新
2. **转录完成**：
   - 日志显示："Soniox 转录完成！"的提示
3. **智能分割和生成字幕**：
   - 程序会自动调用 LLM 进行智能分割
   - 生成优化后的 SRT 字幕文件
   - 如果启用了 AI 后处理，会继续显示："进行 AI 校对"相关的提示

**第六步：获取结果**

- 转录完成后，在导出目录会生成：
   - `RJ123456.srt`：优化后的字幕文件
   - `RJ123456.json`：Soniox 原始转录结果（用于备份）
   - `校对提示报告RJ123456.txt`: 详细的AI纠错校对报告，即使您没有勾选AI纠错，它也会列举出需要重点关注的句子提高人工校对的效率

- 可以打开 SRT 文件检查转录效果
- 如果发现专有名词识别准确率大幅提升，说明台本辅助功能生效了！

---

### 💡 台本准备最佳实践

**如何准备高质量的台本文件？**

1. **台本来源**：
   - 如果您是创作者，使用原始剧本即可
   - 如果是第三方音声，可以从：
     - 官方提供的台本PDF（部分音声附带）
     - 给作者写邮件求他给你 ( 笑
   
2. **台本格式要求**：
   
   - **TXT 格式**（推荐）：
     - 直接复制粘贴所有对话即可，可以不用导入按钮
     - 如果是导入按钮导入的文本，可以包含动作、音效标记，然后通过清洗功能清洗掉
     - 示例：
       ```
       艾莉娅：你好，初次见面。
       [开门声]
       男主：啊、那个……请问是来应聘的吗？
       艾莉娅：嗯啊~就是这样的……（小声）
       ```
   
   - **Word 格式**：
     
     - 标准 .docx 文件
     
   - **PDF 格式**：
     
     - 程序会自动调用 OCR 识别
     - OCR 需要消耗额外的识别时间
     - 识别准确率取决于 PDF 本身的质量
   
3. **台本内容建议**：
   - ✅ **包含所有对话和旁白**
   - ✅ **可以包含拟声词**（如"哦吼吼~"、"呜呜~"）
   - ✅ **可以包含音效标记**（如 [开门声]）
   - ✅ **可以包含动作描述**（如"抚摸头部"）
   - ⚠️ **不要过度信任LLM清洗**：有时候，保持台本原始状态中的一些拟声词可能会更好，最好亲自把关

4. **台本清洗效果示例**：

   **清洗前（原始台本）**：
   ```
   艾莉娅：你好……(小声说话) 我是艾莉娅·冯·埃伦贝格。
   [开门声]
   男主：啊、那个……(抚摸头部) 请问是来应聘的吗？
   ```

   **清洗后（提取为 Context）**：
   ```
   艾莉娅：你好……我是艾莉娅·冯·埃伦贝格。
   男主：啊、那个……请问是来应聘的吗？
   ```

   **识别效果对比**：
   - ❌ **没有台本**：可能识别成"爱丽亚·冯·爱伦贝格"（错误）
   - ✅ **有台本辅助**：准确识别为"艾莉娅·冯·埃伦贝格"（正确）

---

### ⚠️ 注意事项

1. **台本与音频内容的匹配**：
   - 台本的对话顺序最好和音频一致，但不强求
   - 如果台本内容与音频差异过大（噪声过多），反而可能降低识别率
2. **台本清洗与 LLM**：
   - 台本清洗会消耗少量 LLM API 额度（通常很少）
3. **PDF 台本 OCR 限制**：
   - OCR 识别准确率取决于 PDF 图片质量
   - 如果 PDF 质量较差，建议想办法手动转换成 TXT 格式
4. **批量转录时的注意事项**：
   - 批量转录时，不支持上传台本。建议处理单个文件时使用上传台本功能
   - 如果时批量转录同一个背景的故事，建议写个剧情简介&摘要作为context上传，可以直接点击 "点击编辑" 按钮进行编辑

---

## 🖼️ 背景设置

![Heal-Jimaku 背景设置截图](https://raw.githubusercontent.com/fuxiaomoke/heal-jimaku/main/assets/background_settings_dialog.png)

点击主界面左上角的 **背景设置按钮(🖼️)** 可以打开"背景设置"对话框。这个面板允许您自定义主窗口的背景显示策略。

您可以在以下四种模式中选择：

1. **默认背景图片轮播(推荐)**:
    - 这是默认选项。
    - 程序会从内置的 background 文件夹中随机选择图片作为背景。

2. **使用当前的背景图片作为固定背景**:
    - 将当前主界面上显示的背景图固定下来作为背景，不再随机切换。

3. **选择自定义文件夹轮播背景图**:
    - 允许您通过"自定义设置"区域的"浏览..."按钮选择一个包含您自己图片的文件夹。
    - 程序将随机轮播您指定文件夹中的图片。

4. **选择自定义图片作为固定背景**:
    - 允许您通过"自定义设置"区域的"选择图片..."按钮选择一张特定的图片。
    - 程序将始终使用这张图片作为背景。

**自定义设置区域**：
- **自定义文件夹**: 当选择"自定义文件夹轮播"模式时，此输入框和"浏览..."按钮会激活，用于选择自定义图片文件夹。
- **自定义固定图片**: 当选择"自定义固定图片"模式时，此输入框和"选择图片..."按钮会激活，用于选择单张图片。

**支持的图片格式包括：PNG, JPG, JPEG, BMP, GIF。**

## 🆕 v0.2.2.0 新功能介绍

### Soniox 云端转录功能

详见上方"Soniox 云端转录设置"章节。

### 台本辅助转录与智能清洗

详见上方"Soniox 云端转录设置"章节中的"台本文件上传"部分。

### 用户友好日志系统

程序的日志区域已全面升级，现在会用更易懂的语言显示处理过程：

**用户友好日志的特点**：

- 使用 emoji 增强可读性
- 将技术术语转换为通俗语言
- 提供实时进度状态
- 给出详细的错误提示和建议

## 🔄 批量处理与拖拽处理使用示例

### 批量处理功能

Heal-Jimaku 现在支持批量处理多个文件，大大提高工作效率：

- **批量JSON处理**: 在"本地JSON"模式下，点击"浏览..."按钮时可以选择多个JSON文件进行批量处理。
- **批量音频处理**: 在"云端获取JSON"或"Soniox转录"模式下，点击"浏览..."按钮时可以选择多个音频/视频文件进行批量处理。

**批量处理特点**:
- 自动识别文件数量，智能判断处理模式
- 提供详细的处理进度和日志反馈，实时显示处理状态
- 处理完成后自动重置UI状态，准备下一次批量处理
- 智能错误处理：单个文件失败不会影响其他文件的处理

**批量处理操作流程**:
1. 在相应的模式下按住Ctrl键点击多个文件，或按住Shift键选择连续文件
2. 程序会自动检测到批量选择，显示文件数量信息
3. 点击"开始转换"后，程序会依次处理每个文件
4. 日志区域会显示每个文件的处理状态和结果
5. 全部完成后显示批量处理汇总信息

### 批量处理示例

**示例1：批量处理JSON文件**
```
1. 选择"本地JSON"模式
2. 点击"浏览..."按钮
3. 按住Ctrl键选择多个JSON文件：episode1.json, episode2.json, episode3.json
4. 程序显示："已选择 3 个JSON文件进行批量处理"
5. 选择导出目录
6. 选择json文件格式
7. 点击"开始转换"
8. 程序依次处理每个文件，生成：episode1.srt, episode2.srt, episode3.srt
```

**示例2：批量处理音频文件**
```
1. 点击"云端获取JSON"按钮
2. 在对话框中点击"浏览..."选择音频文件
3. 按住Ctrl键选择多个音频文件：track1.mp3, track2.mp3, track3.mp3
4. 转录服务商选择ElevenLabs免费版
5. 程序自动设置转录语言为"自动检测"，说话人数为"自动检测"，可根据自身情况手动调整。
6. 确认设置后点击"确定"
7. 选择导出目录
8. 点击"开始转换"
9. 程序依次转录并优化每个音频文件
```

### 拖拽处理功能

支持通过拖拽方式快速处理文件，提供更直观的用户体验：

- **拖拽JSON文件**: 将JSON文件直接拖拽到窗口，支持单个或多个文件
- **拖拽媒体文件**: 将音频/视频文件直接拖拽到窗口，支持单个或多个文件
- **智能识别**: 程序会自动识别文件类型并设置相应的处理模式
- **非法混合检测**: 防止同时拖拽JSON和媒体文件，会弹出警告提示
- **视觉反馈**: 拖拽时窗口会显示半透明的拖拽区域，提供直观的用户体验

**拖拽处理特点**:
- 支持批量拖拽处理，可一次拖拽多个同类型文件
- 提供清晰的拖拽视觉反馈，拖拽区域会高亮显示
- 自动验证文件类型和合法性，防止错误操作
- 与现有处理逻辑无缝集成，无需改变使用习惯
- 拖拽后的操作流程与常规文件选择完全一致

**拖拽操作技巧**:
- 可以从文件资源管理器直接拖拽文件到程序窗口
- 支持从桌面拖拽文件快捷方式
- 拖拽时确保鼠标指针位于程序主窗口区域内
- 程序会自动检测并响应拖拽操作

### 拖拽处理示例

**示例1：拖拽JSON文件**
```
1. 确保程序处于"本地JSON"模式
2. 打开文件资源管理器，找到JSON文件
3. 直接拖拽文件到程序窗口
4. 程序自动识别文件类型并加载
5. 继续正常的处理流程
```

**示例2：拖拽音频文件**
```
1. 从文件资源管理器选择音频文件
2. 拖拽到程序窗口
3. 程序自动打开"云端转录设置"对话框
4. 设置转录参数
5. 确认后继续处理流程
```

## 📝 具体操作步骤

应用程序提供两种主要的工作流程：

### A. 使用本地 JSON 文件进行优化

1. **输入 API Key**:

   - 在 "大模型 API KEY 设置"区域的 "API Key" 输入框中，粘贴您的 LLM API Key。

   - 或者，打开 "LLM高级设置"窗口，依照上面的大模型配置教程自定义API Key。

     注意：如果您希望下次启动时自动填充，请勾选 "记住 API Key"。

2. **(可选) 调整各项设置**:

   - 点击主界面左上角的 **SRT高级参数设置按钮 (⚙)** 调整SRT字幕生成参数。
   - 点击主界面左上角的 **LLM高级设置按钮 (🤖)** 调整API地址、模型等LLM参数。
   - 根据您的需求调整相关参数，然后点击"确定"保存。如果不需要修改，可以跳过此步骤。

3. **选择 JSON 文件**:

   - 确保主界面处于"本地JSON"模式（这是默认模式，或者如果您从"云端获取JSON"模式取消后也会恢复到此模式）。
   - 点击 "文件选择" 区域中 "JSON 文件" 旁边的 "浏览..." 按钮。**现在支持拖拽处理选择，可拖拽选择。**
   - 在弹出的文件对话框中，找到并选择您要处理的 JSON 文件。**现在支持多文件选择，可进行批量处理。**

4. **选择 JSON 格式**:

   - 在 "文件选择" 区域的 "JSON 格式" 下拉框中，根据您的JSON文件来源选择对应的格式。

5. **选择导出目录**:

   - 点击 "导出与控制" 区域中 "导出目录" 旁边的 "浏览..." 按钮。
   - 选择您希望保存生成的 SRT 文件的文件夹。

6. **开始转换**:

   - 确认以上信息无误后，点击 "开始转换" 按钮。

### B. 使用"云端获取JSON"功能从音频直接生成优化字幕

1. **输入LLM API Key**:
- 同上，确保 LLM API Key 已设置。这是后续文本分割所必需的。
2. **(可选) 调整各项设置**:

   - 您可以预先设置好期望的SRT输出参数和LLM配置。
3. **打开云端转录设置对话框**:
   - 点击主界面"文件选择"区域的 **"云端获取JSON"按钮**。
   - 或者，您可以**直接使用拖拽功能，拖拽一个或多个媒体文件到主窗口中**。
4. **设置转录参数并选择音频文件**:
   - 在弹出的"云端转录设置"对话框中，点击“转录服务商”下拉列表，选择符合您需求的服务商
     - ElevenLabs WEB/免费版：个人比较推荐，基础效果和付费版没区别，白嫖党首选，非常擅长应对复杂场景，对非语言声音非常敏感，超级适合同人音声的转录
     - ElevenLab API/付费版：有钱人的最佳选择，可自定义功能较多，隐私性强和且不用考虑文件大小限制
     - Soniox API/付费版：在打轴任务上，性价比最高，自定义功能多，基础识别准确率不如ElevenLabs，不过可以靠context提升。建议不那么刺激的“低语”类作品用这个。

   - 点击"浏览..."选择您的音频/视频文件。**现在支持多文件选择，可进行批量音频处理。在批量音频处理模式下，转录语言和说话人数将强制使用自动检测，无法手动修改。**
   - 根据需要调整不同转录服务的"转录参数"。
     - ElevenLabs WEB/免费版：
       1. 目标语言
       2. 说话人数
       3. 标记音频事件

     - ElevenLab API/付费版：
       1. API Key（包含测试按钮测试API连接性）
       2. 目标语言
       3. 说话人数
       4. 说话人分离
       5. 标记音频事件

     - Soniox API/付费版：
       1. API Key
       2. 语言提示&自动语言识别
       3. 说话人分离
       4. context优化
          - 专有名词（一行一个，可自己编辑）
          - 剧情设定（非结构化文本，可自己编辑或点击导入按钮导入，支持llm清洗）

   - 点击"确定"。主界面将更新，JSON文件相关控件会被禁用，JSON输入框会显示您选择的音视频文件名（或批量音视频的数量），"云端获取JSON"按钮变为"取消获取JSON"按钮。

5. **选择导出目录**:
   - 同上，选择SRT文件的保存位置。
6. **开始转换**:
   - 点击 "开始转换" 按钮。程序会首先调用STT服务进行在线转录，生成JSON数据保存在导出目录，然后使用此数据进行后续的LLM智能分割和SRT优化。最后在导出文件夹生成SRT文件（选择Soniox服务的话还会生成校对报告）。

---

### 通用后续步骤 (两种模式共有)

1. **监控进度与日志**:

   - 在转换过程中，您可以观察进度条的变化，该进度条会反映包括获取摘要、文本分块及逐块调用LLM进行分割的整体进度。
   - 日志区域会输出详细信息，包括与API的交互（免费STT API、Soniox API 和 LLM API）、**获取全文摘要的过程、文本如何被分块、逐块调用LLM API进行分割的情况**、文本片段的对齐情况、字幕条目的调整等。优化后的日志逻辑会提供更清晰的步骤说明。如果出现任何问题，错误信息也会在此显示。
2. **获取 SRT 文件**:

   - 当转换完成后，进度条会达到 100%，并且会弹出提示框告知结果。
   - 生成的 SRT 文件将保存在您选择的导出目录中。

## 📔 配置与日志文件

- **用户配置**:

  - 路径: `~/.heal_jimaku/config/config.json` (`~` 代表用户主目录)
  - 内容: 保存 API Key (可选)、上次使用的JSON/音频路径、上次使用的输出路径、上次选择的JSON格式、上次输入模式，以及图片管理相关参数、自定义的高级SRT参数、LLM配置参数、ElevenLabs转录相关参数、Soniox 转录参数。

- **崩溃日志**:
  - 路径: `~/.heal_jimaku/logs/heal_jimaku_crashes.log`
  - 内容: 如果应用程序意外崩溃，此文件会记录 Python 的错误回溯信息。

## 🔍 故障排查

### 通用错误

- **"缺少信息" / "错误" 弹窗**:
  - 确保 API Key (用于LLM分割)、导出目录都已正确填写或选择。
  - **本地JSON模式**: 检查JSON文件路径是否已选择，文件是否存在且可读，并且其内容与所选的JSON格式相符。
  - **免费云端转录模式**: 确保已通过对应对话框选择了一个有效的音频/视频文件。
  - **付费云端转录模式**: 确保已选择音频/视频文件，并且 对应服务商的 API Key 已配置。

### API 相关错误

- **LLM API**:
  - **首选排查方式**: 请首先使用 **"LLM高级管理" (🤖) -> "测试连接"** 按钮。它会提供最直接的错误反馈（如API Key无效、模型名称错误等）。
  - **API格式配置错误**: 这是一个常见的错误点。请确保您在"LLM高级管理"中选择的 **"API格式"** 与您填写的 **"API地址"** 严格对应。（例如：DeepSeek/OpenAI 对应 "OpenAI兼容"；Anthropic 对应 "Claude格式"）。
  - **认证失败 (401/400/403)**: 请检查您的 API Key 是否正确，以及账户余额是否充足。不同服务商返回的代码不同（OpenAI/Claude: 401, Gemini: 400）。
  - **模型未找到 (404 Not Found)**: 检查您在"LLM高级管理"中填写的 "模型" 名称是否正确，或者"API格式"是否选错（例如用"OpenAI兼容"格式去请求一个Claude的模型名称）。
  - **请求超时 (Timeout)**: 网络连接问题或 LLM API 服务繁忙。可以稍后重试。**由于长文本处理包含多次API调用（摘要+分块分割+台本清洗），请确保网络连接在整个处理过程中保持稳定**。
  - **API 响应格式错误/内容为空**: 可能是 LLM API 临时问题，或输入文本过于特殊（例如过长，虽然已有分块但仍可能遇到边界情况）导致模型无法处理。**日志中会指明是摘要获取阶段、台本清洗阶段还是特定文本块分割阶段出错**。

- **免费STT服务 (如ElevenLabs)**:
  - **网络错误/超时**: 检查您的网络连接。免费服务可能因网络波动或服务本身负载较高而不稳定。
  - **文件格式/大小问题**: 确保上传的音频文件格式受支持且大小在服务限制内（免费服务对文件大小有300MB的限制）。
  - **API错误**: 日志中可能会显示来自STT服务的具体错误信息。

- **Soniox API**:
  - **API Key 无效**: 检查 Soniox API Key 是否正确复制，没有多余空格。
  - **账户余额不足**: 前往 Soniox Console 检查账户余额并充值。
  - **文件格式不支持**: 确保音频文件格式为 Soniox 支持的格式。
  - **文件过大**: 单个文件建议不超过 500MB，否则可能上传失败。
  - **网络超时**: Soniox 转录需要稳定的网络连接，检查网络状态。
  - **台本上传失败**: 如果上传了台本但转录失败，可能是台本格式问题或 LLM 清洗失败。检查日志中的详细错误信息。

### JSON 解析错误

- **JSON 解析错误 / "无法获取LLM分割用文本" (日志中显示)**:
  - **本地JSON模式**: 确保您在 "JSON 格式" 下拉框中选择了与您的输入文件匹配的正确格式。检查JSON文件本身是否完整且符合其源服务商的规范。
  - **云端转录的免费获取JSON模式**: 如果在线转录失败或返回的JSON不符合预期（非常罕见），可能会出现此问题。检查网络连接并重试。尤其注意，每个IP每天的免费限额是300MB内容，如果超出限额，一定会401失败，请换一个魔法节点。
  - **云端转录的ElevenLabs或者Sonio付费模式**: 如果返回的JSON无法解析，可能是转录失败或网络中断。检查日志中的错误信息。

### 对齐相关问题

- **"LLM 片段无法对齐" / "对齐相似度较低" (日志中显示)**:
  - 这表示 LLM API 返回的文本片段在原始带时间戳的词语中找不到足够相似的匹配。（代码中的v0.2.2.0版本已通过括号修正和时间戳校正算法优化了此问题）。
  - 如果仍然出现，原因可能包括：LLM对文本的改写程度较大、原始JSON中的完整文本字段与词语列表拼接内容不一致等。
  - 少量此类警告通常不影响整体字幕质量。

### 台本相关问题

- **台本清洗失败**:
  - **LLM API 未配置**: 确保已配置好 LLM API Key，台本清洗需要调用 LLM。
  - **LLM API 余额不足**: 检查 LLM 账户余额。
  - **台本格式错误**: 如果是 PDF 台本，可能是 OCR 识别失败。尝试转换为 TXT 格式。
  - **台本内容为空**: 检查台本文件是否有实际内容。

- **PDF 台本 OCR 识别失败**:
  - **PDF 质量较差**: 如果 PDF 是扫描件且质量低，OCR 可能失败。建议手动转换为 TXT。
  - **Dots OCR 服务不可用**: 检查网络连接，或稍后重试。
  - **LLM 清洗失败**: OCR 结果需要 LLM 清洗，确保 LLM API 可用。

- **台本与音频不匹配**:
  - **症状**: 转录完成后，发现识别结果很奇怪，与音频内容不符。
  - **原因**: 上传的台本内容与音频不够匹配（比如在清洗台本时把关键信息当成噪声清洗了）。
  - **解决**: 确保台本和音频对应正确，确保关键信息不丢失。

### 背景图片相关

- **背景图片加载失败 (日志中显示)**:
  - **文件夹无效**: 检查 "背景设置" -> "自定义文件夹" 中选择的路径是否正确且存在。
  - **图片无效**: 检查 "背景设置" -> "自定义固定图片" 中选择的*文件*路径是否正确且存在。
  - **文件夹中没有支持的图片**: 确保您选择的文件夹中包含支持的格式 (PNG, JPG, JPEG, BMP, GIF)。

### 其他问题

- **程序无响应**:
  - 如果转换的文件非常大（尤其是云端转录模式下的大音频文件），API 调用（包括摘要和多次分块分割、台本清洗）和后续处理可能需要较长时间。请耐心等待日志区域的输出和进度条的更新。
  - 如果您上传的是PDF文件，那么OCR识别一般都会花一分钟到两分钟的时间。请不要急着关闭窗口。
  - 如果长时间没有响应，可能是网络连接中断或 API 服务异常。尝试重启程序或检查网络。
  
- **程序崩溃 / 严重错误**:
  - 如果程序意外关闭，请检查位于 `~/.heal_jimaku/logs/heal_jimaku_crashes.log` 的崩溃日志文件。
  - 如果您需要在 GitHub 提交 Issues，请附上此日志文件的内容。

## 🤔 其他问题

### 为啥一定要默认用付费的DeepSeek的api，不能直接用免费接口或者其他更牛逼的大模型的接口嘛？

- 现在程序已支持配置其他主流格式的API！通过LLM高级设置，您可以配置使用其他大语言模型服务。
- 选ds最客观的原因是，在理解并分割日文文本 **（现已扩展至中文、英文、韩文）** 这个任务上，DeepSeek的性价比很高，兼顾了准确性和开销。
- 另一个比较现实的原因是，DeepSeek是国产模型，不用怎么需要担心网络连接的问题。
- 再说了，这个项目一开始是面向同人音声的台本开发的，不可描述的内容比较多，还是用个人付费api比较放心。
- 而且，其他付费接口效果不一定比DeepSeek更好，可能最后答案没有多少差别，至于薅羊毛薅到的免费接口，那就更不清楚了。
- 具体测试效果如下面这张图所示。 可以发现，DeepSeek-v3在面对这种标点符号识别数量很少的文本时，也能在系统提示词 **（现已经已进一步优化，此处图片仅做效果展示）** 的指导下输出不逊于顶尖模型的结果。唯一的不同仅仅是语气词、感叹词或迟疑词的处理，而这些短促的句子，在后续字幕合并优化时间戳的逻辑中是可以被统一的。相较之下，另一个被我寄予厚望的模型——qwen3，由于思考时间过长影响效率，以及实际输出结果不佳的缘故，最终被pass掉了。
  ![多个大模型测试统一文本的效果](https://raw.githubusercontent.com/fuxiaomoke/heal-jimaku/main/assets/test-llm.png)

### 现在支持多种JSON格式了，哪个效果最好？ / "云端获取JSON"功能效果如何？

- **本地JSON模式**: 程序本身对不同格式的解析能力是一致的，最终字幕质量更多取决于原始ASR服务商输出的JSON中，词语时间戳的准确性以及完整文本（尤其是标点断句）的质量。推荐选择您认为转录质量最高、时间戳最精确的服务商输出的JSON。带有 "(推荐)" 标记的格式（如ElevenLabs, Soniox, Whisper）通常是因为这些服务商的模型效果比较好，建议优先尝试。[顺便强烈推荐各位音声同好试试这个我之前经常用的,whisper微调的 [日语特化模型](https://huggingface.co/efwkjn/whisper-ja-anime-v0.1) ，效果不输付费的ElevenLabs]
- **云端获取JSON(免费模式)**: 此功能集成的STT服务（当前为ElevenLabs的免费API）旨在提供一个便捷、高质量的初始转录。其效果通常较好，尤其是对于清晰的常见语言音频。但免费服务可能在处理复杂音频（如多人、背景噪音大、口音特殊）时表现可能会不如付费模型。最终效果还取决于您对免费转录参数（语言、说话人数等）的设置。
- **云端获取JSON(付费费模式)**：预算充足情况下的最佳选择。
  - **ElevenLabs**的付费版在免费版的基础上去除了不少限制，发布至今鲜有敌手。综合成本和转录效果，它就是最适合同人音声转录的云端解决方案。
  - **Soniox**可以配合台本辅助功能使用，有时的转录效果非常夸张，专有名词识别率可达 95% 以上，再加上价格低廉，推荐用于特定的作品（有台本，偏安静）。


### Soniox vs ElevenLabs，应该选哪个？

| 对比项 | ElevenLabs（免费） | ElevenLabs API | Soniox + context辅助 |
|-------|------------------|---------------|-----------------|
| 成本 | 免费 | 按量付费（略高） | 按量付费（较低） |
| 识别精度 | 优秀 | 优秀                         | 良好 |
| 专有名词识别 | 良好 | 良好 | 有context优秀，否则一般 |
| 说话人分离 | 支持 | 支持 | 支持 |
| Context功能 | 不支持 | 不支持 | 支持 |
| 适用场景 | 复杂场景、预算有限 | 复杂场景、预算充足，追求极致 | 有台本、偏安静的场景 |

**推荐选择**：

- **预算有限**：ElevenLabs 免费
- **预算充足/无台本**：ElevenLabs API
- **有台本/拟声词偏少**：Soniox + 台本辅助

### Soniox模式下，上传的台本质量对识别效果的影响大吗？

**非常大！** 台本质量直接影响 Context 功能的效果。

**高质量台本的标准**：

- ✅ 内容完整，包含所有对话
- ✅ 与音频内容匹配度高
- ✅ 对话顺序与音频一致
- ✅ 专有名词拼写准确

**低质量台本可能导致**：

- ❌ 识别率不升反降
- ❌ 错误的专有名词识别
- ❌ 无关内容干扰

**💡 小贴士**：如果台本质量不确定，可以先用小段音频测试效果，再决定是否用于完整转录。

### 如何选择合适的 LLM 服务商？

**按需求选择**：

1. **预算有限 + 国内用户**：
   - 推荐：**DeepSeek**
   - 优势：性价比最高，中日文处理强，无需科学上网
   - 成本：10元可用很久
3. **追求更好的效果&免费**：
   - 推荐：**Gemini**
   - 优势：完全免费（有配额限制）
   - 缺点：需要科学上网，需要有虚拟卡
4. **测试用途&白嫖**：
   - 可以尝试：**公益API**
   - 优势：免费
   - 缺点：不稳定，隐私风险

### 我没有信用卡或者歪果的虚拟卡，怎么使用ElevenLabs或者Soniox服务？

- 最简单的办法当然还是想办法搞一张卡，但我也没办法教你如何稳定的申请到。
- 一个好消息是ElevenLabs每个月有10000点的免费额度，大约可以转录2个半小时的音频，如果你申请10个号，理论上是够用的。
- 不过，更有性价比的Soniox是强制要绑卡的，而且最近没啥活动，所以......
- 不过，如果你是和我一样在大刘哥的平台上做翻译，多少应该会有办法的吧......派安盈的消费卡之类的......
- 实在想尝个鲜的话，来译者群找我，可以看情况送你点儿额度......

### 为什么不直接把这个字幕优化功能加在上一个语音转字幕的项目里？

- 我希望前一个项目更加通用一些，不仅仅局限在日语音声的转录上。
- 而本项目则会更多的聚焦在字幕优化导出上，特别是针对同人音声等场景，例如通过引入摘要理解上下文并对长文本进行分块处理来提升字幕分割质量，以及现在新增的台本辅助转录功能。
- 还有就是，我太菜了，又比较懒惰，所以......
- "云端获取JSON"功能，其实已经借鉴并集成了我之前项目的核心转录逻辑，目标是为用户提供一个更流畅、从音频文件开始的一站式字幕优化体验，减少对外部工具的依赖。

## ⚠️ 注意！！！

使用 **Heal-Jimaku(治幕)** 生成的 SRT 文件的时间戳并不是百分百完美的。如果你需要翻译字幕文件，那么在翻译之前请务必先使用字幕编辑工具(比如subtitle edit)进行简单的人工校对。放心，不符合审核要求的大部分字幕都已经被程序优化过了，你只需要稍微过一遍字幕，把那些我特地留下来的非常容易发现但程序无法处理的小问题手动解决一下即可。

如果遇到无法解决的问题，欢迎在项目的 GitHub Issues 页面提交详细的问题描述以及相关的日志信息。
